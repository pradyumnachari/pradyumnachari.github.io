<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4JB1559LS3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4JB1559LS3');
</script>
	
	
  
  <link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
  <style>
   body {
    font-family: 'Montserrat';font-size: 16px;
   }
   </style>
  <title>Pradyumna Chari</title>
  
  <meta name="author" content="Pradyumna Chari">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!link rel="icon" type="image/png" href="images/Chari.png">
</head>

<body>
  <table style="width:100%;max-width:800;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:#17252A;"><tbody>
  	<tr style="padding:0px">
  		<td style="padding:0px">
  			<table style="width:55%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	          <tr style="padding:0px">
	            <td style="padding:2.5%;width:63%;vertical-align:middle">
	              <h1 style="text-align:center;color:#DEF2F1;font-size:40px;font-weight:bolder">
	                <name>Pradyumna Chari</name>
	              </h1>
	              
	              <p style="text-align:center;color:#FEFFFF">
	                <a style="color:#FEFFFF" href="mailto:pradyumnac@ucla.edu">Email</a> &nbsp/&nbsp
	               
	                <a style="color:#FEFFFF" href="https://scholar.google.com/citations?user=GE0ylLMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
			<a style="color:#FEFFFF" href="https://twitter.com/PradyumnaChari">Twitter</a> &nbsp/&nbsp
	                <a style="color:#FEFFFF" href="https://www.linkedin.com/in/pradyumna-chari-a93544118/">LinkedIn</a>
	              </p>
	            </td>
	            <td style="padding:2.5%;width:40%;max-width:40%">
	              <a href="images/IMG_1630.JPG"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/IMG_1630.JPG" class="hoverZoomLink"></a>
	            </td>
	          </tr>
	        </tbody></table>
  	    </td>
    </tr>
  </tbody>
  </table>

  <table style="width:80%; border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
         <h2 style="color:#2B7A78;font-size:30px;font-weight:bolder">
		      About Me</h2>

        <!table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><!tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
              <!-- <heading>Biography</heading> -->
              <p>
          		I am a fifth year PhD student at the <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/">Visual Machines Group</a>, UCLA, advised by <a style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Prof. Achuta Kadambi</a>. At VMG, we work on developing cutting-edge tools at the intersection of physics and artificial intelligence, to be applied to diverse problems in human-centric computer vision and computational imaging. I have been fortunate to be supported by a CISCO PhD Fellowship for a part of my PhD.
          	  </p>
              <p>
                I completed my Bachelor's degree in Electrical Engineering from the <a style="color:#2B7A78" href="https://www.iitm.ac.in/">Indian Institute of Technology, Madras</a>, India, where I was the President's Gold Medal awardee for outstanding academic performance, for the year 2019. I worked on my undergraduate thesis with <a style="color:#2B7A78" href="http://www.ee.iitm.ac.in/kmitra/">Prof. Kaushik Mitra</a> at the <a style="color:#2B7A78" href="http://www.ee.iitm.ac.in/comp_photolab/">Computational Imaging Lab</a> in the domain of High Dynamic Range imaging.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
              <h2 style="color:#2B7A78;font-size:30px;font-weight:bolder">
		      Updates</h2>
              <ul>
	      	<li>December 2023: Three new preprints on 3D Gaussian splatting and generative methods. </li><br>
	      	<li>July 2023: Summer internship at Snap Research. </li><br>
	      	<li>June 2023: Invited talk at Rice Univeristy. </li><br>
	      	<li>March 2023: Paper accepted to <b>IEEE Access</b>. </li><br>
		<li>September 2022: <b>SIGGRAPH 2022</b> work on equitable computational imaging for heart rate estimation featured by <a style="color:#2B7A78" href="https://dailybruin.com/2022/09/29/ucla-visual-machines-group-develops-biosensor-that-could-eliminate-racial-bias">Daily Bruin</a>. </li><br>
		<li>August 2022: <b>SIGGRAPH 2022</b> work on equitable computational imaging for heart rate estimation featured by <a style="color:#2B7A78" href="https://newsroom.ucla.edu/releases/fixing-skin-tone-bias-in-remote-heart-rate-sensors">UCLA Newsroom</a>. </li><br>
		<li>August 2022: Paper accepted to <b>UIST 2022</b>. </li><br>
		<li>July 2022: Paper accepted to <b>ECCV 2022</b>. </li><br>
		<li>May 2022: Paper accepted to <b>SIGGRAPH 2022</b>. </li><br>
		<li>March 2022: Paper accepted to <b>CVPR 2022</b>. </li><br>
		<li>August 2021: Awarded the <b>CISCO PhD Fellowship</b> for work in remote health sensing. </li> <br>
		<li>October 2020: Our paper, <i>Diverse RPPG: Camera-based Heart Rate Estimation for Diverse Subject Skin Tones and Scenes</i>, is up on ArXiv. </li><br>    
              	<li>Novemeber 2019: Our paper, <i>Visual Physics: Discovering Physical Laws from Videos</i>, is up on ArXiv.</li> <br>
<!--               	<b>Links:</b> <a href="https://arxiv.org/pdf/1911.11893.pdf">Paper</a>, <a href="https://visual.ee.ucla.edu/visualphysics.htm">Webpage</a> </li> -->
<!--               	<br> -->
              	<li>October 2019: Awarded the President of India Prize, Bharat Ratna M Visvesvaraya Memorial Prize and the Siemens Prize for outstanding academic performance from IIT Madras. <br>
              	<b>Media and Links:</b> <a style="color:#2B7A78" href="http://www.ee.iitm.ac.in/2019/09/convocation-prize-winners-2019/">IIT Madras</a>, <a style="color:#2B7A78" href="https://www.ee.ucla.edu/pradyumna-chari-prof-kadambis-student-receives-the-president-of-india-gold-medal-from-the-indian-institute-of-technology-madras/">UCLA</a>, <a style="color:#2B7A78" href="https://www.thehindu.com/news/cities/chennai/in-a-first-girl-bags-president-of-india-prize/article29560538.ece">The Hindu</a>, <a style="color:#2B7A78" href="https://www.jagranjosh.com/current-affairs/kavitha-gopal-becomes-first-girl-student-to-win-president-of-india-prize-1569908631-1">Jagranjosh</a>  </li>
              	<br>
              	<li>March 2019: Awarded the Graduate Dean's Scholars Award from the University of California, Los Angeles in 2019, in recognition of prior academic excellence.</li>
              </ul>
            </td>
          </tr>
        </tbody></table>


        <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
              <h2 style="color:#2B7A78;font-size:30px;font-weight:bolder">
		      Research</h2>
              <p>
                 My research interests lie at the intersection of applied deep learning and computer vision/computational imaging. My current work relates to developing <b><i>tools for rendering and 3D representation in the era of novel generative priors</i></b>. I am also interested in aspects of <b><i>fairness in the era of learning-based vision systems</i></b> and <b><i>equitable health sensing</i></b>.             
	      </p>
              <p>
              	In the past, I have worked on more traditional imaging projects. As part of my undergraduate thesis, I worked on developing <b><i>novel regimes for HDR imaging with new camera setups</i></b>. I have also worked on minor projects in <b><i>lensless imaging</i></b> and <b><i>camera calibration regimes for large camera networks</i></b>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		
	<table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2 style="color:#2B7A78;font-size:30px;font-weight:bolder">Selected Papers</h2>
              <p><i>
          		* indicates equal contribution
		      </i></p>
            </td>
          </tr>
        </tbody></table>
	
        <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
	
	  <tr> 
		  
	
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/mime.png"><img style="width:100%;max-width:100%" src="images/mime.png" class="hoverZoomLink"></a>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/mime.htm/">
                <papertitle>MIME: Minority Inclusion for Majority Group Enhancement of AI Performance</papertitle>
              </a>
              <br>
              <strong>Pradyumna Chari</strong>,
              <a style="color:#2B7A78" href="https://yhba-ucla.github.io">Yunhao Ba</a>,
	      <a style="color:#2B7A78" href="https://shreeramathreya.github.io">Shreeram Athreya</a>,
              <a style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <p></p>
              <p> Some inclusion of minority samples improves test error for the majority group.</p>
	      <br>
              <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/mime.htm/">Project Webpage</a>
              
            </td>
          </tr> 
	  
	   <tr> 
		  
	
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/siggraph_611_represent.jpg"><img style="width:100%;max-width:100%" src="images/siggraph_611_represent.jpg" class="hoverZoomLink"></a>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a style="color:#2B7A78" href="https://dl.acm.org/doi/10.1145/3528223.3530161">
                <papertitle>Blending Camera and 77 GHz Radar Sensing for Equitable, Robust Plethysmography</papertitle>
              </a>
              <br>
	      <a style="color:#2B7A78" href="https://asvilesov.github.io">Alexander Vilesov</a>*,
              <strong>Pradyumna Chari*</strong>,
	      <a style="color:#2B7A78" href="https://adnan-armouti.github.io">Adnan Armouti</a>*,
              <a style="color:#2B7A78" href="https://anirudh0707.github.io">Anirudh B H</a>,
	      Kimaya Kulkarni,
	      Ananya Deoghare,
	      Laleh Jalilian,
              <a style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>ACM Trans. Graph. (SIGGRAPH)</em>, 2022
              <br>
              <p></p>
              <p>A multimodal fusion approach between camera and radar to achieve more equitable and robust plethysmography.</p>
	      <br>
              <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/equi_pleth_camera_rf.htm/">Project Webpage</a>
              
            </td>
          </tr>
		
	  <tr> 
		  
	
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/rppg_generation_thumbnail.png"><img style="width:100%;max-width:100%" src="images/rppg_generation_thumbnail.png" class="hoverZoomLink"></a>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a style="color:#2B7A78" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.pdf">
                <papertitle>Synthetic Generation of Face Videos with Plethysmograph Physiology</papertitle>
              </a>
              <br>
	      <a style="color:#2B7A78" href="https://zhenwangwz.github.io">Zhen Wang</a>*,
	      <a style="color:#2B7A78" href="https://yhba-ucla.github.io">Yunhao Ba</a>*,
              <strong>Pradyumna Chari</strong>,
	      Oyku Deniz Bozkurt,
	      Gianna Brown,
	      Parth Patwa,
	      Niranjan Vaddi,
	      Laleh Jalilian,
              <a style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <p></p>
              <p>A scalable biophysical neural rendering method to generate biorealistic synthetic rPPG videos given any reference image and target rPPG signal as input.</p>
	      <br>
              <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/rppg_avatars.htm/">Project Webpage</a>
              
            </td>
          </tr>
	

            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/video_demo.gif"><img style="width:100%;max-width:100%" src="images/video_demo.gif" class="hoverZoomLink"></a>

            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a style="color:#2B7A78" href="https://arxiv.org/abs/2010.12769">
                <papertitle>Diverse RPPG: Camera-based Heart Rate Estimation for Diverse Subject Skin Tones and Scenes</papertitle>
              </a>
              <br>
              <strong>Pradyumna Chari*</strong>,
              <a style="color:#2B7A78" href="https://krishk97.github.io">Krish Kabra</a>*,
		    Doruk Karinca,
		    Soumyarup Lahiri, 
		    Diplav Srivastava, 
		    Kimaya Kulkarni, 
		    Tianyuan Chen, 
		    Maxime Cannesson, 
		    Laleh Jalilian,
              <a style="color:#2B7A78" style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>ArXiv</em>, 2020
              <br>
              <p></p>
              <p>Identifying and solving underlying bias in remote heart rate monitoring using consumer camera systems based on noise analysis.</p>
	      <br>
	  	<a style="color:#2B7A78" href="https://visual.ee.ucla.edu/diverse_rppg.htm/">Project Webpage</a>
             
            </td>
          </tr>


          <tr> 
		  
	
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/thumbnail.png"><img style="width:100%;max-width:100%" src="images/thumbnail.png" class="hoverZoomLink"></a>
 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a style="color:#2B7A78" href="https://arxiv.org/abs/1911.11893">
                <papertitle>Visual Physics: Discovering Physical Laws from Videos</papertitle>
              </a>
              <br>
              <strong>Pradyumna Chari*</strong>,
              <a style="color:#2B7A78" href="https://chinmay0301.github.io/">Chinmay Talegaonkar</a>*,
              <a style="color:#2B7A78" href="https://yhba-ucla.github.io/">Yunhao Ba</a>*,
              <a style="color:#2B7A78" href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>ArXiv</em>, 2019
              <br>
              <p></p>
              <p>A novel pipeline that enables discovery of underlying parameters and equations from videos of physical phenomena.</p>
	      <br>
              <a style="color:#2B7A78" href="https://visual.ee.ucla.edu/visualphysics.htm">Project Webpage</a>
              
            </td>
          </tr>
          
          
        </tbody></table> 

   
        <table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template credits: <a style="color:#2B7A78" href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
